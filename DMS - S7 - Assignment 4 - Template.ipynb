{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation of books\n",
    "Author: Luke Huisman<br>\n",
    "Student number: 684651<br>\n",
    "Date: 26-03-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working within this notebook, please ensure that you have activated your virtual environment (venv). Activating the venv ensures that you are using the correct versions of the packages required for this notebook.\n",
    "\n",
    "### Activating the venv\n",
    "\n",
    "To activate the venv, use the following commands:\n",
    "\n",
    "- On Windows:\n",
    "    ```sh\n",
    "    .\\venv\\Scripts\\activate\n",
    "    ```\n",
    "\n",
    "- On macOS/Linux:\n",
    "    ```sh\n",
    "    source venv/bin/activate\n",
    "    ```\n",
    "\n",
    "### No venv yet?\n",
    "\n",
    "If you have not yet created a virtual environment, you can do so by running the following command in your terminal:\n",
    "\n",
    "```sh\n",
    "python -m venv venv\n",
    "```\n",
    "After creating the venv, you will need to install one package manually. This package is `ipykernel`, which is required for Jupyter Notebook to work properly. You can install it by running the following command:\n",
    "\n",
    "```sh\n",
    "pip install ipykernel\n",
    "```\n",
    "Once you have activated the venv and installed the required packages, you can start working within this notebook. If you encounter any issues or have questions, please feel free to reach out for assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries\n",
    "For this notebook to work you must have installed the following packages:\n",
    "* pandas\n",
    "* matplotlib\n",
    "\n",
    "For your convenience, the notebook will check if these packages are installed. If not, it will install them for you. **MAKE SURE TO ACTIVATE YOUR VENV FIRST!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    print(f\"Installing {package}, please wait...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    install('pandas')\n",
    "    import pandas as pd\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    install('matplotlib')\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Item-Based Recommender\n",
    "\n",
    "We are going to build an item-based recommender for books. In this recommender we could for example recommend books that are similar to a book that a user has already read.\n",
    "\n",
    "To begin you'll need to download the dataset from [kaggle](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset). Move the dataset to the [/data](/data) folder and extract the files in there. The dataset contains a few files, but we won't be using all of them.\n",
    "\n",
    "We'll only be using the books.csv and ratings.csv files. The books.csv file contains information about the books, and the ratings.csv file contains information about the ratings that users have given to the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes():\n",
    "    try:\n",
    "        books_df: pd.DataFrame = pd.read_csv('data/books.csv')\n",
    "        ratings_df: pd.DataFrame = pd.read_csv('data/ratings.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Please download the data file(s) from kaggle repository and or rename them accordingly.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    return books_df, ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a quick look at the data head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df, ratings_df = load_dataframes()\n",
    "print(books_df.head())\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the dataset is quite extensive, but it also has a lot of unneccesary columns. We can for example from the books dataset drop all columns except for the ISBN and the Book-Title as we won't be needing the other columns for the recommender system.\n",
    "\n",
    "We furthermore will clean the data a little bit before hand by removing any ratings that are 0, as these are not useful for our recommender system. We will also remove any entries where the user has given multiple ratings for the same book, as this is likely an error in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_dataframes(books_df, ratings_df):\n",
    "    # Only select from the books_df the columns ISBN and Book-Title\n",
    "    books_df = books_df[['ISBN', 'Book-Title']]\n",
    "\n",
    "    # Remove all rows from the ratings_df where the Book-Rating is 0\n",
    "    ratings_df = ratings_df[ratings_df['Book-Rating'] != 0]\n",
    "\n",
    "    # Remove all duplicate ratings where the same user rated the same book multiple times\n",
    "    ratings_df = ratings_df.drop_duplicates(subset=['ISBN', 'User-ID'])\n",
    "\n",
    "    # Merge the two dataframes on the ISBN column\n",
    "    df = books_df.merge(ratings_df, on='ISBN')\n",
    "\n",
    "    return df\n",
    "df = cleanup_dataframes(books_df, ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been picked, we can take another look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already looks a lot better. We can see that the data is now much more readable and that we have removed a lot of the unnecessary columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to take the counts into consideration so lets keep those into their own dataframe, together with the average score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe where each row is a book and the columns are the average rating and the number of ratings\n",
    "average_ratings = df.groupby('ISBN')['Book-Rating'].agg(['mean', 'count'])\n",
    "# Reset the index so that ISBN is a column\n",
    "average_ratings.reset_index(inplace=True)\n",
    "# Rename the columns to Average-Rating and Number-of-Ratings\n",
    "average_ratings.columns = ['ISBN', 'Average-Rating', 'Number-of-Ratings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide on a cut-off point as minimum number of scores to be eligable we can plot the number of scores in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(average_ratings['Average-Rating'], bins=10)\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(average_ratings['Number-of-Ratings'], bins=100)\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram we can see that there are a lot of book with a lot amount of ratings, while most books have very few ratings. We can see that the majority of books have less than 100 ratings. We can use this information to decide on a cut-off point. We can for example decide that a book needs at least 25 ratings to be eligible for the recommender system.\n",
    "\n",
    "Let's drop all rows where the number of ratings is less than 25 and take another peek at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply minimum rating count threshold\n",
    "min_ratings = 25\n",
    "average_ratings = average_ratings[average_ratings[\"Number-of-Ratings\"] >= min_ratings]\n",
    "\n",
    "plt.hist(average_ratings[\"Average-Rating\"], bins=10)\n",
    "plt.xlabel(\"Average Rating\")\n",
    "plt.ylabel(\"Number of Books\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(average_ratings[\"Number-of-Ratings\"], bins=100)\n",
    "plt.xlabel(\"Number of Ratings\")\n",
    "plt.ylabel(\"Number of Books\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many of the very low ratings have been removed from the dataset. We can loosly conclude that the ratings and books that have been removed are not very popular or were outliers in the dataset. Making the dataset more reliable for our recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can create the code to perform a recommendation. First we can select one particular book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random book for recommendation\n",
    "book = average_ratings.sample(random_state=42).merge(books_df, on=\"ISBN\")\n",
    "selected_book_isbn = book[\"ISBN\"].values[0]\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need one row per user, and his/her scores for each book. We can do this by creating a pivot table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the main dataset to include only books meeting the threshold\n",
    "df = df[df['ISBN'].isin(average_ratings['ISBN'])]\n",
    "\n",
    "# Create a pivot table where the rows are the User-ID, the columns are the ISBN, and the values are the Book-Rating\n",
    "pivot_table = df.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then to find the recommendation based on the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation with additional filtering\n",
    "def compute_correlation(isbn, pivot_table, min_total_ratings=25):\n",
    "    min_ratings = 5 # Minimum number of ratings for a book to be considered for correlation\n",
    "\n",
    "    if isbn not in pivot_table:\n",
    "        return None\n",
    "\n",
    "    book_ratings = pivot_table[isbn]\n",
    "    ratings_count = (pivot_table.notna().astype(int).T.dot(book_ratings.notna().astype(int)))\n",
    "\n",
    "    valid_books = ratings_count[ratings_count >= min_ratings].index\n",
    "    valid_books = valid_books[average_ratings[average_ratings['ISBN'].isin(valid_books)]['Number-of-Ratings'] >= min_total_ratings]\n",
    "\n",
    "    correlation = pivot_table[valid_books].corrwith(book_ratings)\n",
    "\n",
    "    correlation_df = pd.DataFrame(correlation, columns=[\"Correlation\"]).dropna()\n",
    "    correlation_df = correlation_df.merge(average_ratings, on=\"ISBN\")\n",
    "\n",
    "    # Exclude the ISBN being searched for from the recommendations\n",
    "    correlation_df = correlation_df[correlation_df[\"ISBN\"] != isbn]\n",
    "\n",
    "    return correlation_df.sort_values(by=\"Correlation\", ascending=False)\n",
    "\n",
    "# Get the top 10 books with the highest correlation\n",
    "top_10_books = compute_correlation(selected_book_isbn, pivot_table, 20).head(10)\n",
    "print(top_10_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest correlation book (0.946) is almost perfectly correlated with \"Beloved.\" This suggests that users who liked \"Beloved\" also highly rated this book. <br>\n",
    "\n",
    "Harry Potter (ISBN: 059035342X) appears in the recommendations. This could be due to its wide readership rather than direct thematic similarity.<br>\n",
    "\n",
    "Lower-correlation books still have decent ratings, but they share fewer overlapping reviewers with the selected book.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be nice to have one simple function that could do all the work for us. It should have as input parameters a dataframe, specific field, and minimum number of ratings, and then returns the recommendation.\n",
    "\n",
    "Note that you should first select the fields that meet the minimum number of ratings, and then perform the correlation matrix, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(df, isbn, min_total_ratings):\n",
    "    df = df[df['ISBN'].isin(average_ratings['ISBN'])]\n",
    "\n",
    "    pivot_table = df.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
    "\n",
    "    # Compute correlation with additional filtering\n",
    "    return compute_correlation(isbn, pivot_table, min_total_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the function:<br>\n",
    "Take for example the book \"The Fellowship of the Ring\" (ISBN: `0618002227`) and see what the recommender system comes up with.<br>\n",
    "Take for example the book \"The Da Vinci Code\" (ISBN: `0385504209`) and see what the recommender system comes up with.<br>\n",
    "Take for example the book \"Jurassic Park\" (ISBN: `0345370775`) and see what the recommender system comes up with.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function should return a dataframe with the top 10 recommendations based on the correlation with the selected book.\n",
    "while True:\n",
    "    input_isbn = input(\"Enter the ISBN of the book you want recommendations for: \")\n",
    "    if input_isbn in average_ratings['ISBN'].values:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid ISBN. Please try again.\")\n",
    "        print(\"Available ISBNs:\")\n",
    "        print(average_ratings.sample(10, random_state=None).merge(books_df, on=\"ISBN\")[['ISBN', 'Book-Title']])\n",
    "\n",
    "# Let the user choose the number of minimum ratings\n",
    "while True:\n",
    "    try:\n",
    "        min_total_ratings = int(\n",
    "            input(\n",
    "                f\"Enter the minimum number of ratings (default is 25): \"\n",
    "            )\n",
    "            or min_total_ratings\n",
    "        )\n",
    "        if min_total_ratings > 0:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please enter a positive integer.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a positive integer.\")\n",
    "\n",
    "# Generate recommendations\n",
    "reccommendations = generate_recommendations(df, input_isbn, min_total_ratings)\n",
    "reccommendations = reccommendations.merge(books_df, on=\"ISBN\")[[\"ISBN\", \"Book-Title\", \"Correlation\", \"Average-Rating\", \"Number-of-Ratings\"]]\n",
    "print(reccommendations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><center>-----Chapters 1 is required to be fully completed to get a 60, the next few chapters will give a +10 for each chapter.<br> \n",
    "    However no template is available for these chapters. You will have to create it yourself.\n",
    "    ----</center></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Negative correlations\n",
    "\n",
    "The recommenders so far used, are looking at what if I give a high rating for this, what do you then recommend me. But how about if I give a low rating for something, what would you then recommend me?\n",
    "\n",
    "Explain how and why your solution works, and how to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Content Based\n",
    "\n",
    "Add a chapter showing how a basic content based recommender might work. A starting point for this might be https://www.datacamp.com/community/tutorials/recommender-systems-python (at about 1/3 of the page it starts explaining this in the section called ‘Content based’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. User Based\n",
    "\n",
    "Add a chapter showing how a basic user based recommender might work. A starting point for this might be https://realpython.com/build-recommendation-engine-collaborative-filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Combination\n",
    "\n",
    "Combine two or more recommendation techniques to get an even better recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
