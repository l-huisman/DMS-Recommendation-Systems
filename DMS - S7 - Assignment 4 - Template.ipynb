{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation of books\n",
    "Author: Luke Huisman<br>\n",
    "Student number: 684651<br>\n",
    "Date: 22-03-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working within this notebook, please ensure that you have activated your virtual environment (venv). Activating the venv ensures that you are using the correct versions of the packages required for this notebook.\n",
    "\n",
    "To activate the venv, use the following commands:\n",
    "\n",
    "- On Windows:\n",
    "    ```sh\n",
    "    .\\venv\\Scripts\\activate\n",
    "    ```\n",
    "\n",
    "- On macOS/Linux:\n",
    "    ```sh\n",
    "    source venv/bin/activate\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook to work you must have installed the following packages (usually via pip install *packageName*:\n",
    "* pandas\n",
    "\n",
    "From these we will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    print(f\"Installing {package}, please wait...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    install('pandas')\n",
    "    import pandas as pd\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    install('matplotlib')\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Item-Based Recommender\n",
    "\n",
    "We are going to build an item-based recommender for books. In this recommender we could for example recommend books that are similar to a book that a user has already read.\n",
    "\n",
    "To begin you'll need to download the dataset from [kaggle](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset). Move the dataset to the [/data](/data) folder and extract the files in there. The dataset contains a few files, but we won't be using all of them.\n",
    "\n",
    "We'll only be using the books.csv and ratings.csv files. The books.csv file contains information about the books, and the ratings.csv file contains information about the ratings that users have given to the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code to load your example data file(s)\n",
    "try:\n",
    "    books_df: pd.DataFrame = pd.read_csv('data/books.csv')\n",
    "    ratings_df: pd.DataFrame = pd.read_csv('data/ratings.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Please download the data file(s) from kaggle repository.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a quick look at the data head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(books_df.head())\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the dataset is quite extensive, but it also has a lot of unneccesary columns. We can for example from the books dataset drop all columns except for the ISBN and the Book-Title as we won't be needing the other columns for the recommender system.\n",
    "\n",
    "We furthermore will clean the data a little bit before hand by removing any ratings that are 0, as these are not useful for our recommender system. We will also remove any entries where the user has given multiple ratings for the same book, as this is likely an error in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select from the books_df the columns ISBN and Book-Title\n",
    "books_df = books_df[['ISBN', 'Book-Title']]\n",
    "\n",
    "# Remove all rows from the ratings_df where the Book-Rating is 0\n",
    "ratings_df = ratings_df[ratings_df['Book-Rating'] != 0]\n",
    "\n",
    "# Remove all duplicate ratings where the same user rated the same book multiple times\n",
    "ratings_df = ratings_df.drop_duplicates(subset=['ISBN', 'User-ID'])\n",
    "\n",
    "# Merge the two dataframes on the ISBN column\n",
    "df = books_df.merge(ratings_df, on='ISBN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been picked, we can take another look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already looks a lot better. We can see that the data is now much more readable and that we have removed a lot of the unnecessary columns.\n",
    "\n",
    "We need one row per user, and his/her scores for each book. We can do this by creating a pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table where the rows are the User-ID, the columns are the ISBN, and the values are the Book-Rating\n",
    "pivot_table = df.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to take the counts into consideration so lets keep those into their own dataframe, together with the average score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe where each row is a book and the columns are the average rating and the number of ratings\n",
    "average_ratings = df.groupby('ISBN')['Book-Rating'].agg(['mean', 'count'])\n",
    "# Reset the index so that ISBN is a column\n",
    "average_ratings.reset_index(inplace=True)\n",
    "# Rename the columns to Average-Rating and Number-of-Ratings\n",
    "average_ratings.columns = ['ISBN', 'Average-Rating', 'Number-of-Ratings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide on a cut-off point as minimum number of scores to be eligable we can plot the number of scores in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(average_ratings['Average-Rating'], bins=10)\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(average_ratings['Number-of-Ratings'], bins=100)\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram we can see that there are a lot of book with a lot amount of ratings, while most books have very few ratings. We can see that the majority of books have less than 100 ratings. We can use this information to decide on a cut-off point. We can for example decide that a book needs at least 25 ratings to be eligible for the recommender system.\n",
    "\n",
    "Let's drop all rows where the number of ratings is less than 25 and take another peek at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ratings = average_ratings[average_ratings[\"Number-of-Ratings\"] >= 25]\n",
    "\n",
    "plt.hist(average_ratings[\"Average-Rating\"], bins=10)\n",
    "plt.xlabel(\"Average Rating\")\n",
    "plt.ylabel(\"Number of Books\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(average_ratings[\"Number-of-Ratings\"], bins=100)\n",
    "plt.xlabel(\"Number of Ratings\")\n",
    "plt.ylabel(\"Number of Books\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many of the very low ratings have been removed from the dataset. We can loosly conclude that the ratings and books that have been removed are not very popular or were outliers in the dataset. Making the dataset more reliable for our recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can create the code to perform a recommendation. First we can select one particular book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab one random book from the average_ratings dataframe with a seed for reproducibility\n",
    "book = average_ratings.sample(random_state=42)\n",
    "# Merge the book with the books_df dataframe to get the title of the book\n",
    "book = book.merge(books_df, on='ISBN')\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then to find the recommendation based on the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation between the selected book and all other books\n",
    "correlation = pivot_table.corrwith(pivot_table[book['ISBN'].values[0]])\n",
    "\n",
    "# Create a new dataframe with the correlation values, drop any rows with missing values, and merge with the average_ratings dataframe.\n",
    "correlation_df = pd.DataFrame(correlation, columns=['Correlation'])\n",
    "correlation_df.dropna(inplace=True)\n",
    "correlation_df = correlation_df.merge(average_ratings, on='ISBN')\n",
    "correlation_df.sort_values(by='Correlation', ascending=False, inplace=True)\n",
    "\n",
    "top_10_books = correlation_df.head(10)\n",
    "print(top_10_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='background:yellow'>\\<interpret the result></span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be nice to have one simple function that could do all the work for us. It should have as input parameters a dataframe, specific field, and minimum number of ratings, and then returns the recommendation.\n",
    "\n",
    "Note that you should first select the fields that meet the minimum number of ratings, and then perform the correlation matrix, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for a python function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test the function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><center>-----Chapters 1 is required to be fully completed to get a 60, the next few chapters will give a +10 for each chapter.<br> \n",
    "    However no template is available for these chapters. You will have to create it yourself.\n",
    "    ----</center></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Negative correlations\n",
    "\n",
    "The recommenders so far used, are looking at what if I give a high rating for this, what do you then recommend me. But how about if I give a low rating for something, what would you then recommend me?\n",
    "\n",
    "Explain how and why your solution works, and how to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Content Based\n",
    "\n",
    "Add a chapter showing how a basic content based recommender might work. A starting point for this might be https://www.datacamp.com/community/tutorials/recommender-systems-python (at about 1/3 of the page it starts explaining this in the section called ‘Content based’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. User Based\n",
    "\n",
    "Add a chapter showing how a basic user based recommender might work. A starting point for this might be https://realpython.com/build-recommendation-engine-collaborative-filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Combination\n",
    "\n",
    "Combine two or more recommendation techniques to get an even better recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
